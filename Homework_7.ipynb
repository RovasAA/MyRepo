{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача: запустить модель LDA и Gibbs Sampling с числов тегов 20. Вывести топ-10 слов по каждому тегу. Соотнести полученные теги с тегами из датасета, сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=frozenset({'put', 'thence', 'except', 'him', 'thereby', 'forty', 'go', 'meanwhile', 'whereupon', 'wherever', 'it', 'mill', 'than', 'least', 'eight', 'over', 'anyhow', 'sometime', 'along', 'because', 'five', 'behind', 'without', 'front', 'whether', 'why', 'any', 'noone', 'ever', 'eleven', ...ong', 'them', 'less', 'thin', 'all', 'had', 'con', 'take', 'eg', 'mostly', 'un', 'else', 'already'}),\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0.01, max_df=0.95,lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word', binary=True)\n",
    "vectorizer.fit(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1142)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(newsgroups_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "предварительная работа проведена, теперь алгоритм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X_train.nonzero()\n",
    "a=np.transpose(a)\n",
    "z=np.zeros(X_train.shape,dtype = np.int8)\n",
    "nkw=np.zeros((20,X_train.shape[1]))\n",
    "ndk=np.zeros((20,X_train.shape[0]))\n",
    "nk=np.zeros(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a :\n",
    "    c=np.random.randint(20)\n",
    "    z[i[0],i[1]]=c\n",
    "    nkw[c,i[1]]+=1\n",
    "    ndk[c,i[0]]+=1\n",
    "    nk[c]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=50/X_train.shape[1]\n",
    "def LDA(X_train,nkw,ndk,nk,z) :\n",
    "    p=np.zeros(20)\n",
    "    for j in range(1000) :\n",
    "        for i in a:\n",
    "            ndk[z[i[0],i[1]],i[0]]-=1\n",
    "            nkw[z[i[0],i[1]],i[1]]-=1\n",
    "            nk[z[i[0],i[1]]]-=1\n",
    "            for k in range(20) :\n",
    "                p[k]=(ndk[k,i[0]]+1/20)*(nkw[k,i[1]]+beta)/(nk[k]+50)\n",
    "            p=p.cumsum()\n",
    "            v=np.random.rand()\n",
    "            v=v*p[-1]\n",
    "            for k in range(20) :\n",
    "                if p[k] > v :\n",
    "                    z[i[0],i[1]]=k\n",
    "                    break\n",
    "            ndk[z[i[0],i[1]],i[0]]+=1\n",
    "            nkw[z[i[0],i[1]],i[1]]+=1\n",
    "            nk[z[i[0],i[1]]]+=1\n",
    "    return z,ndk,nkw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,ndk,nkw=LDA(X_train,nkw,ndk,nk,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "полечаем теги с такими топ 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Topic: { don just know like ll people really say think want }\n",
      "2 Topic: { don government gun just law people right rights state think }\n",
      "3 Topic: { believe does don just know like people point say think }\n",
      "4 Topic: { file like problem running set thanks use using window windows }\n",
      "5 Topic: { april government national new people states today world year years }\n",
      "6 Topic: { ca com cs edu email fax internet mail phone university }\n",
      "7 Topic: { don good just know like really think time ve way }\n",
      "8 Topic: { chip clipper data encryption government just key keys phone public secure }\n",
      "9 Topic: { available free including information list note number provide send use }\n",
      "10 Topic: { 10 11 12 13 14 15 16 17 20 25 }\n",
      "11 Topic: { does drive hard just know like problem thanks use work }\n",
      "12 Topic: { does file files ftp know like program thanks use version windows }\n",
      "13 Topic: { advance appreciated does hi information know like mail post thanks }\n",
      "14 Topic: { bible christ christian christians does god jesus life people say }\n",
      "15 Topic: { buy car cars don good just know like really think }\n",
      "16 Topic: { bit bus card does memory pc speed use video windows }\n",
      "17 Topic: { game games good like play players season team think year }\n",
      "18 Topic: { ago did didn got just said saw time went years }\n",
      "19 Topic: { best condition edu interested new offer price sale sell shipping }\n",
      "20 Topic: { high just like low power space time use used using }\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "  mask = (nkw[i] >= np.sort(nkw[i])[-10])\n",
    "  print(\"%d Topic: {\" % (i + 1), \" \".join(vectorizer.inverse_transform(mask)[0]),\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё раз выведем названия топиков ,которые были даны изначально: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем их соотнести с нашими топиками после применения алгоритма:\n",
    "\n",
    "    1)Напримар тег  'soc.religion.christian' хорошо соотносится с Топиком №14:\n",
    "            { bible christ christian christians does god jesus life people say }\n",
    "    2)тег 'talk.politics.guns' хорошо соотносится с Топиком №2:\n",
    "        { don government gun just law people right rights state think }\n",
    "    3)тег 'talk.politics.mideast'   хорошо соотносится с Топиком №5:\n",
    "        { april government national new people states today world year years }  \n",
    "    4)тег 'rec.sport.hockey'   хорошо соотносится с Топиком №17:\n",
    "        { game games good like play players season team think year }\n",
    "    5)тег 'misc.forsale'   хорошо соотносится с Топиком №19:\n",
    "        { best condition edu interested new offer price sale sell shipping }\n",
    "    6)тег 'comp.windows.x'   хорошо соотносится с Топиком №4\n",
    "    7)тег 'comp.sys.ibm.pc.hardware'   хорошо соотносится с Топиком №6\n",
    "    8)тег 'sci.electronics'   хорошо соотносится с Топиком №8\n",
    "    9)тег 'comp.graphics'   хорошо соотносится с Топиком №16\n",
    "    И ещё несколько соотношений\n",
    "Исходя из этих наблюдений, делаем вывод что алгоритм восстанавлиает почти такое же разбиение на темы, но всё же не полностью, а лишь частично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
